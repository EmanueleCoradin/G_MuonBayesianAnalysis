---
title: "Unbinned Analysis"
author: "Emanuele Coradin"
date: "`r Sys.Date()`"
output: 
  read_document: rmdformats::readthedown
  pdf_document:
    number_sections: true
    toc: true
    toc_depth: 2
  html_document:
    number_sections: true
    theme: spacelab
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

color_vector <- c("#CC0000",   # Dark red
                  "#CC79A7",   # Muted purple
                  "#D55E00",   # Vermilion
                  "#009E73",   # Bluish green
                  "#56B4E9",   # Sky blue
                  '#000046',   # Deep Blue
                  "#DB1E60",   # Pinkish-red
                  "#E69F00")   # Yellow-orange

```

```{r, message=FALSE, echo=FALSE}
library(rjags)
library(ggplot2)
library(dplyr)
library(coda)
```

# Bayesian analysis of the $\mu^+$ and $\mu^-$ lifetime in aluminum

## Introduction

The goal of this project is to obtain the lifetimes of positive and negative muons in aluminium. The given dataset contains the time passed between the implantation of the muon and its decay. 

In this document I'm exploring the following idea: 
we have three possible kinds of event, decay of either positive or negative muon or a background event. The first two will follow an exponential distribution, even though having different decay constants, while the background follows a uniform distribution. A weighted average of them will give the distribution of the data.  In this way it is possible to avoid the construction of an histogram (unbinned analysis).

## Useful functions

```{r functions}
getGammaParam <- function(mean, variance) {
  beta <- mean / variance
  alpha <- mean * beta
  c(alpha = alpha, beta = beta)
}

getBetaParam <- function(mean, variance) {
  nu <- mean * (mean * (1 - mean) / variance - 1)
  alpha <- mean * nu
  beta <- nu * (1 - mean)
  c(alpha = alpha, beta = beta)
}

prior_moments <- c(
  tau_mean = 2.1,
  tau_var = 0.05^2,
  alpha_mean = 1/3,
  alpha_var = 0.3,
  omega_mean = 4.77,
  omega_var = (4.77 * 0.04)^2 / 12,
  delta_mean = 0,
  delta_var = 0.32
)

PriorParam <- list(
  tau = getGammaParam(prior_moments['tau_mean'], prior_moments['tau_var']),
  omega = getGammaParam(prior_moments['omega_mean'], prior_moments['omega_var']),
  delta = getBetaParam((prior_moments['delta_mean'] + pi/2) / pi, prior_moments['delta_var'] * pi^-2),
  alpha = getBetaParam((prior_moments['alpha_mean'] + 1/3) / (4/3), prior_moments['alpha_var'] / (4/3)^2)
)

PriorParam
```

## Data Loading

```{r }
# Read files
paths_lifetime   <-dir('g-2data/data/lifetime/2023_24', pattern ='^t', full.names=TRUE)
paths_precession <-dir('g-2data/data/precession/2023_24', full.names=TRUE)

data_lifetime   <-numeric()
data_precession <- numeric()

for (path in paths_lifetime)   {data_lifetime   <- as.integer(c(data_lifetime, (readLines(path))))}
for (path in paths_precession) {data_precession <- as.integer(c(data_precession, (readLines(path))))}


# Calibrate data
p0       <- 7.4
sigma_p0 <- 4.4
p1       <- 14.90
sigma_p1 <- 0.11

calibrate <- function(x) (p0 + p1 * x)*1e-3

data_lifetime   <- calibrate(data_lifetime)
data_precession <- calibrate(data_precession)

# Cleaning the dataset
data_lifetime   <- data_lifetime[data_lifetime<8]
data_precession <- data_precession[data_precession<6]
cat('Length data_lifetime=',length(data_lifetime),'\n')
cat('Length data_precession',length(data_precession))
```

## Test

```{r }
# Load necessary library
#install.packages("stats4")  # Run this line if you haven't installed the package yet
library(stats4)

# Define the decay probability density function
decay_pdf <- function(t, tau, alpha, omega, delta) {
  FACTOR <- alpha * (cos(delta)-tau*omega*sin(delta)) + tau^2*omega^2
  exp(-t / tau) * (1 + alpha * cos(omega * t + delta))*(1+tau^2*omega^2)/tau/(1+FACTOR)
}

# Define the negative log-likelihood function
neg_log_likelihood <- function(tau, alpha, omega, delta) {
  -sum(log(decay_pdf(t, tau, alpha, omega, delta)))
}

# Load your data
#data <- read.csv("/mnt/data/your_dataset.csv")  # Adjust the path to your file
t <- data_precession

# Set initial parameter guesses
initial_params <- list(tau = 2.2, alpha = 1/3, omega = 4.7, delta = 0)
lower_bounds <- c(tau = 1.5, alpha = 0.0001, omega = 4, delta = -pi)
upper_bounds <- c(tau = 3, alpha = 1, omega = 5.5, delta = pi)

# Fit the model using Maximum Likelihood Estimation (MLE)
fit <- mle(neg_log_likelihood, start = initial_params, method = "L-BFGS-B", lower = lower_bounds, upper = upper_bounds)

# Get the fitted parameters
fitted_params <- coef(fit)
tau <- fitted_params["tau"]
alpha <- fitted_params["alpha"]
omega <- fitted_params["omega"]
delta <- fitted_params["delta"]

# Output the results
print(fitted_params)

```
```{r}
# Load necessary library
#install.packages("stats")  # Run this line if you haven't installed the package yet
library(stats)

# Load your data
#data <- read.csv("/mnt/data/your_dataset.csv")  # Adjust the path to your file
t <- data_precession

# Calculate the Fourier Transform
fft_result <- fft(t)

# Remove the zero-frequency component
fft_result[1] <- 0

# Compute the corresponding frequencies
n <- length(t)
dt <- mean(diff(t))  # Mean difference in time intervals
frequencies <- (0:(n-1)) / (n * dt)

# Compute the amplitude spectrum
amplitude <- Mod(fft_result)

# Plot the amplitude spectrum without the zero-frequency component
plot(frequencies[-1], amplitude[-1], type = "h", xlab = "Frequency (Hz)", ylab = "Amplitude", main = "Fourier Transform of Decay Data")

# Find the dominant frequencies
dominant_freqs <- frequencies[order(-amplitude)]
print(dominant_freqs[2:6])  # Print the top 5 dominant frequencies excluding the zero-frequency

```

## Lifetime Analysis 

```{r}
zeros <- rep(0, length(data_lifetime))
dataList <- list(x = data_lifetime, zeros=zeros)

# Write JAGS model
modelString <- sprintf("
  
#model {
#    for (i in 1:length(x)) {
#      zeros[i] ~ dpois(zeros.mean[i])
#      zeros.mean[i] <- -L[i]
#      L[i] <- -x[i]/tau - log(tau)
#    }
#    tau ~ dunif(1.9,3)
#}

#model{
#  for (i in 1:length(x)) {
#    x[i] ~ dexp(1/tau)
#  }

  # Prior
#  tau ~ dunif(1.9,3)
#}

model {

  for (i in 1:length(x)) {
      zeros[i] ~ dpois(zeros.mean[i])
      zeros.mean[i] <- -L[i]
      L[i] <- log((1-noise_signal)*(exp(-x[i]/tau)/tau) + noise_signal)
  }
  
  noise_signal <- 0
  tau ~ dgamma(%.2f, %.2f)
}", PriorParam$tau["alpha"], PriorParam$tau["beta"])

# Save the model string to a file
writeLines(modelString, con = "model.jags")

```
```{r}
# Run the model
jagsModel <- jags.model(file = "model.jags", 
                        data = dataList, 
                        n.chains = 1, 
                        n.adapt = 100)

#variable.names= c('tau','tau_minus', 'fraction')
jagsSamples <- coda.samples(model = jagsModel, 
                            variable.names= c('noise_signal', 'tau'), 
                            n.iter = 500)

# Summarize and inspect results
parms <- summary(jagsSamples)$statistics[,'Mean']

summary(jagsSamples)
```

```{r plot-jags, fig.width=10, fig.height=8}
#X11(width = 10, height = 8)

plot(jagsSamples)
```

```{r}
posterior_matrix <- as.matrix(jagsSamples)

# Retrieve the chains
tau_samples <- posterior_matrix[, "tau"]

par(mfrow = c(3, 2))


acf(tau_samples, main = "Autocorrelation of tau")
```


## Precession

```{r}
# Load required libraries
install.packages("rjags")
library(rjags)
library(ggplot2)
library(bayesplot)

# Read data from files
read_data_from_files <- function(directory) {
  files <- list.files(directory, pattern = "\\.dat$", full.names = TRUE)
  all_data <- numeric()
  for (file in files) {
    data <- scan(file, quiet = TRUE)
    all_data <- c(all_data, data)
  }
  return(all_data)
}

# Directory containing the data files
data_directory <- "/home/ema/Desktop/Documents/GitHub/MuonLifetimeBayesianAnalysis/g-2data/data/precession/2023_24"

# Read the data
t_data <- read_data_from_files(data_directory)

# Calibration and filtering
t_data <- (14.90 * t_data + 7.4) * 1e-3  # Apply calibration
t_data <- t_data[(t_data > 1) & (t_data < 7)]  # Filter data

# Prepare the data for JAGS
jags_data <- list(
  t_data = t_data,
  N = length(t_data),
  zeros = rep(0, length(t_data))
)

# Write the JAGS model to a file
model_string <- "
model {
  for (i in 1:N) {
    zeros[i] ~ dpois(zeros.mean[i])
    zeros.mean[i] <- -L[i]
    L[i] <- -t_data[i] / tau + log(1 + alfa * cos(omega * t_data[i] + delta)) - log(tau) - log(FACTOR)
  }
  
  tau ~ dunif(1.9, 3)
  delta ~ dunif(-3.14, 3.14)
  omega ~ dunif(4.2, 5.2)
  alfa ~ dunif(0, 1)
  
  FACTOR <- 1 + alfa / (1 + tau^2 * omega^2) * (cos(delta) - tau * omega * sin(delta))
}
"
writeLines(model_string, con = "model_precession.txt")

# Initial values for the parameters
inits <- function() {
  list(tau = runif(1, 1.9, 3), delta = runif(1, -3.14, 3.14), omega = runif(1, 4.2, 5.2), alfa = runif(1, 0, 1))
}

# Parameters to monitor
parameters <- c("tau", "delta", "omega", "alfa")

# Model
model <- jags.model("model_precession.txt", data = jags_data, inits = inits, n.chains = 3, n.adapt = 1000)

# Burn-in
update(model, 1000)

# MCMC
samples <- coda.samples(model, variable.names = parameters, n.iter = 10000)

# Summarize the results
summary(samples)

# Extract the parameter estimates
mcmc_results <- as.data.frame(do.call(rbind, samples))

# Summary of MCMC results
print(summary(mcmc_results))

# Plot the posterior distributions
mcmc_trace(samples)
mcmc_hist(samples)

# Extract the means of the fitted parameters
tau_fitted <- mean(mcmc_results$tau)
delta_fitted <- mean(mcmc_results$delta)
omega_fitted <- mean(mcmc_results$omega)
alfa_fitted <- mean(mcmc_results$alfa)

cat(sprintf("Fitted parameters: tau = %f, delta = %f, omega = %f, alfa = %f\n", tau_fitted, delta_fitted, omega_fitted, alfa_fitted))

# Create data frame for the fitted PDF
t_values <- seq(min(t_data), max(t_data), length.out = 1000)
fitted_pdf <- function(t) {
  exp(-t / tau_fitted) * (1 + alfa_fitted * cos(omega_fitted * t + delta_fitted))
}
fitted_pdf_values <- fitted_pdf(t_values)
fitted_pdf_data <- data.frame(t = t_values, density = fitted_pdf_values)

# Create a histogram and plot the fitted PDF
hist_data <- data.frame(t = t_data)
ggplot(hist_data, aes(x = t)) +
  geom_histogram(aes(y = ..density..), bins = 30, fill = "blue", alpha = 0.6) +
  geom_line(data = fitted_pdf_data, aes(x = t, y = density), color = "red", size = 1) +
  labs(x = "Time (t)", y = "Probability Density") +
  theme_minimal()

```
```{r , fig.width=10, fig.height=8}
plot(posterior_sample)
```
