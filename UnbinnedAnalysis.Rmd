---
title: "Unbinned Analysis"
author: "Emanuele Coradin"
date: "`r Sys.Date()`"
output: 
  read_document: rmdformats::readthedown
  pdf_document:
    number_sections: true
    toc: true
    toc_depth: 2
  html_document:
    number_sections: true
    theme: spacelab
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

color_vector <- c("#CC0000",   # Dark red
                  "#CC79A7",   # Muted purple
                  "#D55E00",   # Vermilion
                  "#009E73",   # Bluish green
                  "#56B4E9",   # Sky blue
                  '#000046',   # Deep Blue
                  "#DB1E60",   # Pinkish-red
                  "#E69F00")   # Yellow-orange

```

```{r, message=FALSE, echo=FALSE}
library(rjags)
library(ggplot2)
library(dplyr)
```

# Bayesian analysis of the $\mu^+$ and $\mu^-$ lifetime in aluminum

## Introduction

The goal of this project is to obtain the lifetimes of positive and negative muons in aluminium. The given dataset contains the time passed between the implantation of the muon and its decay. 

In this document I'm exploring the following idea: 
we have three possible kinds of event, decay of either positive or negative muon or a background event. The first two will follow an exponential distribution, even though having different decay constants, while the background follows a uniform distribution. A weighted average of them will give the distribution of the data.  In this way it is possible to avoid the construction of an histogram (unbinned analysis).

## Functions and default values

```{r Default values}
bins_default <- 120

prior_moments <- c(
  tau_mean = 2.1,
  tau_var = 0.05^2,
  alpha_mean = 1/3,
  alpha_var = 0.3,
  omega_mean = 4.77,
  omega_var = (4.77 * 0.04)^2 / 12,
  delta_mean = 0,
  delta_var = 0.32
)
```

```{r functions}
getGammaParam <- function(mean, variance) {
  beta <- mean / variance
  alpha <- mean * beta
  c(alpha = alpha, beta = beta)
}

getBetaParam <- function(mean, variance) {
  nu <- mean * (mean * (1 - mean) / variance - 1)
  alpha <- mean * nu
  beta <- nu * (1 - mean)
  c(alpha = alpha, beta = beta)
}

fitting<-function(law,parms,data,name, scale='lin', ...) {
  p<-plotdata(data, name, scale=scale, ...)
  if (scale=='lin'){ p<-p+geom_line(aes(data,law(data,parms)))}
  else if (scale == 'log') { p<-p+geom_line(aes(data,log10(law(data,parms))))}
  p
}

plotdata <- function(data, name, histdata = NULL, scale = 'lin', bins = bins_default, plot_histbar = FALSE, xlim = NULL) {
  if (is.null(histdata)) histdata <- hist(data, breaks = bins, plot = FALSE)
  
  df <- data.frame(mids = histdata$mids, counts = histdata$counts)
  
  # Calculate standard error for each bin
  if (scale == "lin") {
    df <- df %>%
      mutate(se = sqrt(counts)) # Standard error as sqrt of counts (Poisson distribution assumption)
  } else {
    df <- df %>%
      mutate(se = 1 / sqrt(counts)) # Standard error as 1/sqrt(counts)
  }
  
  p <- ggplot() + theme_minimal()
  
  if (plot_histbar) {
    p <- p + geom_bar(data = df, aes(x = mids, y = counts), stat = "identity", fill = 'blue', color = 'blue')
    if (scale == "log") {
      p <- p + scale_y_log10()
    }
  } else {
    if (scale == "lin") {
      p <- p + geom_point(data = df, aes(x = mids, y = counts), color = 'blue', size = 1) +
        geom_errorbar(data = df, aes(x = mids, ymin = counts - se, ymax = counts + se), width = 0.2)
    } else {
      p <- p + geom_point(data = df, aes(x = mids, y = log10(counts)), color = 'blue', size = 1) +
        geom_errorbar(data = df, aes(x = mids, ymin = log10(counts) - se, ymax = log10(counts) + se), width = 0.2)
    }
  }
  
  if (!is.null(xlim)) {
    p <- p + xlim(xlim)
  }
  
  p
}


PriorParam <- list(
  tau = getGammaParam(prior_moments[['tau_mean']], prior_moments[['tau_var']]),
  omega = getGammaParam(prior_moments[['omega_mean']], prior_moments[['omega_var']]),
  delta = getBetaParam((prior_moments[['delta_mean']] + pi/2) / pi, prior_moments[['delta_var']] * pi^-2),
  alpha = getBetaParam((prior_moments[['alpha_mean']] + 1/3) / (4/3), prior_moments[['alpha_var']] / (4/3)^2)
)

```

## Data Loading and Filtering


```{r }
# Read files
paths_lifetime   <-dir('g-2data/data/lifetime/2023_24', pattern ='^t', full.names=TRUE)
paths_precession <-dir('g-2data/data/precession/2023_24', full.names=TRUE)

data_lifetime   <-numeric()
data_precession <- numeric()

for (path in paths_lifetime)   {data_lifetime   <- as.integer(c(data_lifetime, (readLines(path))))}
for (path in paths_precession) {data_precession <- as.integer(c(data_precession, (readLines(path))))}

cat('Length data_lifetime=',length(data_lifetime),'\n')
cat('Length data_precession',length(data_precession))

# Calibrate data
p0       <- 7.4
sigma_p0 <- 4.4
p1       <- 14.90
sigma_p1 <- 0.11

calibrate <- function(x) (p0 + p1 * x)*1e-3

data_lifetime   <- calibrate(data_lifetime)
data_precession <- calibrate(data_precession)

# Cleaning the dataset
data_lifetime   <- data_lifetime[data_lifetime<8]
data_precession <- data_precession[data_precession>1 & data_precession<6]

```

## Lifetime Analysis 

```{r}
dataList <- list(x = data_lifetime)

init_values <- list(list(tau = 2.2))

n_burnin <- 5000  # Length of the burn-in phase
thinning <- 2
Nrep     <- 2000 # Number of values to simulate
n_adapt  <- 1000

# Write JAGS model
model_lifetime_def <- sprintf("
model{
  for (i in 1:length(x)) {
    x[i] ~ dexp(1/tau)
  }

  tau ~ dgamma(%.2f, %.2f)
}", PriorParam$tau["alpha"], PriorParam$tau["beta"])

model_lifetime <- jags.model(file = textConnection(model_lifetime_def), data = dataList, inits = init_values, n.chains = 1, n.adapt = n_burnin)

# Adaptation phase
adapt(model_lifetime, n_adapt)

# Burn-in phase
update(model_lifetime, n.iter = n_burnin)

# Sample from the posterior
posterior_lifetime <- coda.samples(model_lifetime, variable.names = c('tau'), n.iter = Nrep, thin = thinning)
(summary_lifetime <- summary(posterior_lifetime))
plot(posterior_lifetime)

posterior_matrix <- as.matrix(posterior_lifetime)

# Retrieve the chains
tau_samples <- posterior_matrix[, "tau"]

acf(tau_samples, main = "Autocorrelation of tau")
```

## Precession Analysis

```{r }
tau_lifetime_posterior <- getGammaParam(summary_lifetime$statistics[['Mean']] ,summary_lifetime$statistics[['SD']])

```

```{r}

dataList = list(x = data_precession, zeros = rep(0, length(data_precession)))

init_values <- list(
  list(delta_base = 0.4, omega = 4.7, alpha_base = 0.4, tau=2.2)
)

n_burnin <- 1000  # Length of the burn-in phase
thinning <- 2
Nrep     <- 10000 # Number of values to simulate
n_adapt  <- 1000

model_precession_def <- sprintf("
model {
  for (i in 1:length(x)) {
    zeros[i] ~ dpois(zeros.mean[i])
    zeros.mean[i] <- -L[i]
    L[i] <- -x[i]/tau + log(1+alpha*cos(omega*x[i]+delta)) - log(tau) - log(FACTOR)
  }
  
  delta_base ~ dbeta(%.2f, %.2f) 
  omega ~ dgamma(%.2f, %.2f)
  alpha_base ~ dbeta(%.2f, %.2f) 
  tau ~ dgamma(%.2f, %.2f)
  
  delta <- delta_base * 3.14 - 3.14/2
  alpha <- alpha_base * 4/3 - 1/3
  
  FACTOR <- 1 + alpha/(1+tau^2*omega^2) * (cos(delta)-tau*omega*sin(delta))
}
", PriorParam$delta["alpha"], PriorParam$delta["beta"], 
   PriorParam$omega["alpha"], PriorParam$omega["beta"],  
   PriorParam$alpha["alpha"], PriorParam$alpha["beta"], 
   tau_lifetime_posterior["alpha"], tau_lifetime_posterior["beta"])


# Create the model
model_precession <- jags.model(file = textConnection(model_precession_def), data = dataList, inits = init_values, n.chains = 1, n.adapt = n_burnin)

# Adaptation phase
adapt(model_precession, n_adapt)

# Burn-in phase
update(model_precession, n.iter = n_burnin)


# Sample from the posterior
posterior_precession <- coda.samples(model_precession, variable.names = c('delta', 'omega', 'alpha', 'tau'), n.iter = Nrep, thin = thinning)
summary(posterior_precession)
posterior_matrix <- as.matrix(posterior_precession)

# Retrieve the chains
delta_samples <- posterior_matrix[, "delta"]
omega_samples <- posterior_matrix[, "omega"]
alpha_samples <- posterior_matrix[, "alpha"]
tau_samples <- posterior_matrix[, "tau"]

par(mfrow = c(2, 2))

acf(delta_samples, main = "Autocorrelation of delta")
acf(omega_samples, main = "Autocorrelation of omega")
acf(alpha_samples, main = "Autocorrelation of alpha")
acf(tau_samples, main = "Autocorrelation of tau")
```
```{r , fig.width=10, fig.height=8}
plot(posterior_precession)
```
